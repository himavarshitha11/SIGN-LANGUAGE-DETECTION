# SIGN-LANGUAGE-DETECTION 

This project is a real-time Sign Language Detection system that uses a webcam to recognize hand gestures and display the corresponding word on the screen.

It can help bridge the communication gap between people who use sign language and those who do not understand it.

ğŸ“¸ Example Output

When a user shows the sign for Hello, the system detects it and displays the word "Hello" on the screen.


âš™ï¸ Features

Detects hand gestures in real-time using a webcam.

Converts gestures into text displayed on the screen.

Works with commonly used sign gestures.

Lightweight and runs on most laptops/desktops with a webcam.

ğŸ› ï¸ Technologies Used

Python 3.9

TensorFlow / Keras â€“ Deep Learning model

OpenCV â€“ Real-time video capture

MediaPipe / cvzone â€“ Hand landmark detection

NumPy â€“ Data processing

ğŸš€ How to Run

Clone or download the project.

Install the required dependencies:

pip install tensorflow==2.9.1 opencv-python mediapipe cvzone numpy keras pyttsx3


Run the prediction script:

python prediction_wo_gui.py


The webcam will open. Show a hand gesture, and the system will display the detected word on the screen.

ğŸ“‚ Project Files

cnn8grps_rad1_model.h5 â†’ Trained deep learning model.

final_pred.py â†’ Script for running detection.

prediction_wo_gui.py â†’ Script to test detection without GUI.

dataset collection scripts â†’ Used to capture training data.

ğŸ”® Future Improvements

Support for more sign gestures.

Add speech output (convert text to voice).

Improve accuracy with larger datasets.

ğŸ™Œ Acknowledgement

This project is made for learning and research purposes to support sign language communication.
